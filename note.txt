Trong quá trình fine-tuning với O-LoRa, có 1 vấn đề là với lượng dữ liệu nhỏ, nhiều dữ liệu bị lặp ý sẽ dẫn đến việc ép trực giao đột ngột có thể khiến mô hình không kịp thích nghi. Điều này dẫn đến hiện tượng loss tăng đột biến ngay sau bước orthogonalization.
Nguyên nhân chính là vì các vector trong ma trận A và B của LoRA đang dần học các hướng trùng lặp. Khi bị ép trực giao ngay lập tức các vector đó buộc phải thay đổi hướng một cách không tự nhiên — mô hình “mất trí nhớ” về những gì vừa học, từ đó làm gián đoạn quá trình tối ưu hóa đang diễn ra.
Thay vì dùng QR decomposition, ta áp dụng một hình thức trực giao hóa mềm bằng cách sử dụng chuẩn hóa vector (L2 normalization): F.normalize(A, p=2, dim=1)


0: LM Loss: 8.6405, CLoRA Loss: 0.2400
0: LM Loss: 8.0518, CLoRA Loss: 0.2400
  2%|███▏                                                                                                                                                                                        | 1/60 [00:22<22:06, 22.49s/it]1: LM Loss: 8.1945, CLoRA Loss: 0.2400
Orthogonalized 196 COLoRA modules
1: LM Loss: 8.6781, CLoRA Loss: 0.2400
  3%|██████▎                                                                                                                                                                                     | 2/60 [01:23<43:53, 45.40s/it]2: LM Loss: 8.5931, CLoRA Loss: 0.2400
2: LM Loss: 8.2263, CLoRA Loss: 0.2400
Orthogonalized 196 COLoRA modules
  5%|█████████▍                                                                                                                                                                                  | 3/60 [02:19<47:38, 50.15s/it]3: LM Loss: 8.3619, CLoRA Loss: 0.2109
3: LM Loss: 8.7895, CLoRA Loss: 0.2109
  7%|████████████▌                                                                                                                                                                               | 4/60 [03:14<48:26, 51.90s/it]4: LM Loss: 7.7643, CLoRA Loss: 0.2109
Orthogonalized 196 COLoRA modules
4: LM Loss: 7.5716, CLoRA Loss: 0.2109
  8%|███████████████▋                                                                                                                                                                            | 5/60 [04:11<49:13, 53.69s/it]5: LM Loss: 8.1664, CLoRA Loss: 0.2109
5: LM Loss: 7.7687, CLoRA Loss: 0.2109
Orthogonalized 196 COLoRA modules
 10%|██████████████████▊                                                                                                                                                                         | 6/60 [05:04<48:11, 53.55s/it]6: LM Loss: 7.6300, CLoRA Loss: 0.2109
6: LM Loss: 7.9598, CLoRA Loss: 0.2109
 12%|█████████████████████▉                                                                                                                                                                      | 7/60 [06:05<49:36, 56.15s/it]7: LM Loss: 7.4850, CLoRA Loss: 0.2109
Orthogonalized 196 COLoRA modules
7: LM Loss: 6.9913, CLoRA Loss: 0.2109
 13%|█████████████████████████                                                                                                                                                                   | 8/60 [07:00<48:12, 55.62s/it]8: LM Loss: 8.3068, CLoRA Loss: 0.2109
8: LM Loss: 7.8385, CLoRA Loss: 0.2109
Orthogonalized 196 COLoRA modules
 15%|████████████████████████████▏                                                                                                                                                               | 9/60 [08:02<48:57, 57.59s/it]9: LM Loss: 7.0145, CLoRA Loss: 0.2109
9: LM Loss: 7.5360, CLoRA Loss: 0.2109
 17%|███████████████████████████████▏                                                                                                                                                           | 10/60 [09:03<48:47, 58.54s/it]10: LM Loss: 8.5000, CLoRA Loss: 0.2109
Orthogonalized 196 COLoRA modules
10: LM Loss: 7.6324, CLoRA Loss: 0.2109

https://arxiv.org/html/2406.01775v1
- Khác biệt so với O-Lora gốc:
	- Không học tuần tự học song song:
		+ Tận dụng tri thức chia sẻ giữa các task
		+ Tăng hiệu quả huấn luyện & giảm thời gian
		+ Cập nhật cùng lúc tất cả adapter
		- Một task mạnh có thể “nuốt” task yếu: vd dev có 90, mà support có 10 thì sẽ khiến các task support học kém
		- Ở các vòng cola sau, mặc dù có phần dư nhưng model ko biết đc phần dư của task nào nếu train song song 
	- Cặp adapter A, B dùng chung cho tất cả các task, Tăng khả năng biểu diễn chung, collaboration_weight là trọng số để kết quả của kết hợp shara A và adapter riêng của từng task
	- Thêm collab_loss tính mức tương đồng giữa các task, đảm bảo các adapter không học trùng kiến thức khi không cần thiết.
	- Thêm Hard Routing(để xác định dữ liệu thuộc về task nào), Soft Routing(để tính toán với những dữ liệu ko rõ task) để tính toán cho dừng adapter riêng

Pipelines:
	- Học song song nhiều task qua các cặp adapter A, B, collaboration_weight và task_experts
	- Tận dụng O-LoRA để đảm bảo các task trực giao hóa, tránh học trùng nhau, trong đó collab_loss ép các adapter trực giao với nhau, trong khi orth_loss ép các adapter trực giao với chính chúng
	- Nếu các task quá tương đồng, sẽ tăng collab_loss để ép các adapter phân biệt nhau rõ ràng hơn
	- Nếu các task quá khác biệt, thì shared A/B và trọng số collaboration_weight sẽ giúp chia sẻ tri thức chung, tránh overfitting cho task nhỏ
	- Kết quả mỗi vòng là 1 model duy nhất chứa toàn bộ adapter cho các task đã được huấn luyện song song
	- Vòng tiếp theo fine-tuning dựa trên mô hình đã merge từ vòng trước, tận dụng Kỹ thuật "học phần dư" để tập trung vào những kiến thức chưa học tốt ở vòng trước

Dẫn chứng cho việc trực giao ảnh hưởng đến khả năng học:
https://arxiv.org/abs/2505.11816?utm_source=chatgpt.com
Complementary to prompt based methods, low-rank adaptation based approaches directly update
model parameters in a parameter-efficient manner. InfLoRA [Liang and Li, 2024] constrains the
parameter updates within a predetermined subspace to reduce the interference between tasks. SD-
LoRA [Wu et al., 2025] decouples the learning of the magnitude and direction of LoRA components.
However, both methods confine weight updates in a specific low-rank subspace, which inherently
limits the model’s learning capacity. Unlike these methods, CoSO updates the parameters across a
series of subspaces, enabling the learning of full-rank weights and thereby enhancing the model’s
flexibility.
https://arxiv.org/abs/2503.06213
First, the orthogonal subspace diminishes over tasks, limiting plasticity improvement
Chiến lược cho việc đa dạng hoá dữ liệu với trực giao:
https://arxiv.org/abs/2407.15085
https://arxiv.org/abs/2410.16801
